{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Load necessary libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Load MNIST Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_param = lambda shape: tf.random_normal(shape, dtype=tf.float32)\n",
    "\n",
    "with tf.name_scope(\"IO\"):\n",
    "    inputs = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "    targets = tf.placeholder(tf.float32, [None, 10], name=\"Yhat\")\n",
    "\n",
    "with tf.name_scope(\"LogReg\"):\n",
    "    W = tf.Variable(init_param([784, 10]), name=\"W\")\n",
    "    B = tf.Variable(init_param([10]))\n",
    "    logits = tf.matmul(inputs, W) + B\n",
    "    y = tf.nn.softmax(logits)\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    learning_rate = tf.Variable(0.5, trainable=False)\n",
    "    cost_op = tf.nn.softmax_cross_entropy_with_logits(logits, targets)\n",
    "    cost_op = tf.reduce_mean(cost_op) \n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_op)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(targets,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create TensorFlow graph*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training\n",
      "Epoch: 5 - Error: 0.3686 - Accuracy - 90.58%\n",
      "Epoch: 10 - Error: 0.3192 - Accuracy - 92.03%\n",
      "Epoch: 15 - Error: 0.3007 - Accuracy - 92.36%\n",
      "Epoch: 20 - Error: 0.2882 - Accuracy - 92.47%\n",
      "Epoch: 25 - Error: 0.2827 - Accuracy - 92.99%\n",
      "Epoch: 30 - Error: 0.2782 - Accuracy - 92.12%\n",
      "Epoch: 35 - Error: 0.2783 - Accuracy - 92.86%\n",
      "Epoch: 40 - Error: 0.2733 - Accuracy - 92.85%\n",
      "Epoch: 45 - Error: 0.2704 - Accuracy - 93.25%\n",
      "Epoch: 50 - Error: 0.2693 - Accuracy - 93.23%\n",
      "Epoch: 55 - Error: 0.2680 - Accuracy - 93.15%\n",
      "Epoch: 60 - Error: 0.2663 - Accuracy - 92.03%\n",
      "Epoch: 65 - Error: 0.2657 - Accuracy - 92.50%\n",
      "Epoch: 70 - Error: 0.2648 - Accuracy - 92.82%\n",
      "Epoch: 75 - Error: 0.2631 - Accuracy - 93.29%\n",
      "Epoch: 80 - Error: 0.2639 - Accuracy - 93.51%\n",
      "Epoch: 85 - Error: 0.2624 - Accuracy - 93.30%\n",
      "Epoch: 90 - Error: 0.2614 - Accuracy - 93.16%\n",
      "Epoch: 95 - Error: 0.2600 - Accuracy - 93.43%\n",
      "Epoch: 100 - Error: 0.2595 - Accuracy - 93.21%\n",
      "Epoch: 105 - Error: 0.2589 - Accuracy - 92.32%\n",
      "Converged.\n",
      "Test Cost: 0.3490 - Accuracy: 90.49% \n"
     ]
    }
   ],
   "source": [
    "tolerance = 1e-4\n",
    "# Perform Stochastic Gradient Descent\n",
    "epochs = 1\n",
    "last_cost = 0\n",
    "alpha = 0.7\n",
    "max_epochs = 100\n",
    "batch_size = 50\n",
    "costs = []\n",
    "sess = tf.Session()\n",
    "print \"Beginning Training\"\n",
    "with sess.as_default():\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    sess.run(tf.assign(learning_rate, alpha))\n",
    "    writer = tf.train.SummaryWriter(\"/tmp/tboard\", sess.graph) # Create TensorBoard files\n",
    "    while True:\n",
    "        \n",
    "        num_batches = int(mnist.train.num_examples/batch_size)\n",
    "        cost=0\n",
    "        for _ in range(num_batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            tcost, _ = sess.run([cost_op, train_op], feed_dict={inputs: batch_xs, targets: batch_ys})\n",
    "            cost += tcost\n",
    "        cost /= num_batches\n",
    "\n",
    "        tcost = sess.run(cost_op, feed_dict={inputs: mnist.test.images, targets: mnist.test.labels})\n",
    "            \n",
    "        costs.append([cost, tcost])\n",
    "        \n",
    "        # Keep track of our performance\n",
    "        if epochs%5==0:\n",
    "            acc = sess.run(accuracy, feed_dict={inputs: mnist.train.images, targets: mnist.train.labels})\n",
    "            print \"Epoch: %d - Error: %.4f - Accuracy - %.2f%%\" %(epochs, cost, acc)\n",
    "\n",
    "            # Stopping Condition\n",
    "            if abs(last_cost - cost) < tolerance or epochs > max_epochs:\n",
    "                print \"Converged.\"\n",
    "                break\n",
    "\n",
    "            last_cost = cost\n",
    "            \n",
    "        epochs += 1\n",
    "    \n",
    "    tcost, taccuracy = sess.run([cost_op, accuracy], feed_dict={inputs: mnist.test.images, targets: mnist.test.labels})\n",
    "    print \"Test Cost: %.4f - Accuracy: %.2f%% \" %(tcost, taccuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Perform gradient descent to learn model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = len(costs)\n",
    "costs = np.array(costs)\n",
    "plt.plot(range(epochs), costs[:,0], label=\"Training\")\n",
    "plt.plot(range(epochs), costs[:,1], label=\"Test\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross Entropy\")\n",
    "plt.title(\"Training Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot train curves*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
